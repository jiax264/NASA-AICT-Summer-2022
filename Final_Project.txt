Report on Automated Accessibility Checkers
_______________________________________________________________________________________________________________________________

Rationale

  * Accessibility checkers will catch and miss certain things
 
  * Important to know/measure how "useful" accessibility checkers are
_______________________________________________________________________________________________________________________________

Objectives

  * Produce report for NASA to potentially replace SortSite
  
  * Research and assess several WACs
  
  * Share general information on WACs, manual website testing, and web accessbility
  
  * WAC must be software and spiderable
  
_______________________________________________________________________________________________________________________________

Tasks

_______________________________________________________________________________________________________________________________

Deliverables (will be accessible)

  * Written report in Word or PDF 
  
  OR
  
  * PowerPoint

_______________________________________________________________________________________________________________________________

Resources Required 

  WACs (CALL ESD ONCE THE FINAL WACs ARE CHOSEN)
  
    * Tenon (demo)
    
    * AccessibilityOz (demo)
    
    * SiteImprove (demo)
    
    * SilkTide (demo)
    
    * SortSite (already have)
    
    * DynoMapper (free trial)
    
    * pa11y (free trial)
    
    * Koa11y (free trial)
    
      - Downloaded onto computer (Koa11y.exe file). Paste URL into pop-up window and get your results
      
      - Output is a long HTML file of errors, warnings, and notices
      
      - Catches HTML issues and indicates where in the HTML the issue is
      
      - Only caught one error, two notices on the NASA home page :/
  
   * AMP (demo) (contacted)

     - Responded with Elev11n Community, a page-by-page cloud-based checker (NOT what we want)

       --> Reach out about software-based checker OR move on

   * Axe Monitor (demo) (contacted)

   * PopeTech/WAVE (demo) (contacted)

   * Little Forest (demo) (contacted)

     - Automated testing tool

     - Cloud service, doesn't have FEDRAMP certification (is cloud secure?)

       --> Will take time, but we can probably still get a demo

     - Checks WCAG 2.1

     - "Domain Discovery" = finds websites and generates reports

     - GET THEM: sites (PRIMARY) and requirements (SECONDARY)

   * Odellus (demo) (contacted)
    
 
 Websites
 
    * https://nasa.gov
    
    * https://www.section508.gov/
   
_______________________________________________________________________________________________________________________________

What We're Measuring

1) Usability of checker

2) 508 Compliant

3) Assistance to Manual Testing

4) Amount of error coverage

5) Types of errors found
_______________________________________________________________________________________________________________________________

Timeline

* (Owen) = Owen does it

* (Rio) = Rio does it

* (Owen or Rio) = one of us

* (Owen and Rio) = do individually, then email correspondence

* (Owen and Rio split) = do individually, split work in half (easy stuff so no extensive communication afterwards) 

* (Owen and Rio, but separately) = do individually, then meet in Teams to discuss findings

* (Owen and Rio together) = do work together while meeting in Teams
  
Timeline - 5 weeks total

  Background Research/Acquisition (6/27-7/1) (CALL ESD ABOUT SOFTWARE)
  
    (6/27)
    
      * determine which companies to reach out to / which checkers to investigate (Owen and Rio) 
        - SortSite (yes!), WAVE, Accessibility Insights, SiteImprove, Deque Axe, etc?
          
        - Consider only "spidering" WACs, as opposed to "page-by-page" WACs
          
              --> WAVE, Accessibility Insights = page-by-page
    
              --> Spidering tools = SortSite, SiteImprove
              
              --> Selenium/Axe = open-source spidering tool
              
    (6/28)
              
      * Request demos from vendors (Owen and Rio split) [DONE!]
    
        - Rio: Tenon, AccessibilityOz, SiteImprove, SilkTide
        
        - Owen: AMP, Axe Monitor, PopeTech/WAVE, Little Forest, Odellus
    
      * Download and play with SortSite, pa11y, and koa11y (Owen and Rio) [DONE!]
      

    
    (6/29)
    
      * Finalize websites and requirements (LITERALLY, what do we want?)
      
      * Send websites and requirements to Little Forest and other vendors (Owen and Rio split)
      
      * Read existing consumer reports & get familiarized w format (Owen and Rio split)
        - https://www.nasa.gov/sites/default/files/atoms/files/aoa_neo_report_final_11082018_0.pdf 
        
        - https://www.nasa.gov/sites/default/files/atoms/files/22_20220420_nasa-symposiumnnsa_pae_aoa_methodology_final.pdf 
        
        - https://ntrs.nasa.gov/api/citations/20205008713/downloads/Acoustics_AoA_TWG_VanZante_Final.pdf 
        
      * Schedule follow-up meeting with Little Forest (let's get that demo!) (Rio)
      
      * Respond to PopeTech (Get your stuff together!) (Owen)
            
    (6/30) 
    
      * Perform manual testing on NASA, SEWP, Section 508 to have standard to compare against (Owen & Rio together) 
   
        - schedule meeting(s) w/ each other   
        
     * Send websites and requirements to Little Forest and other vendors (Owen and Rio split)
    
    
  Evaluation Setup - 2 weeks (7/5 - 7/8, 7/11 - 7/15) (CALL ESD ABOUT SOFTWARE)
  
  (7/5 - 7/8)
  
    * Depending on when get access to checkers, get familiarized w/ them as they come in (Owen and Rio, but separately)
    
    * Main task this week is to determine what the report will assess (Owen and Rio)
        - This will be informed by what functionality we observe in the different checkers 
        - Key thing is to not feel boxed in by the categories we set at this point, but do brainstorm what 
        factors/features would be impt to look at 

    * Potential research question(s)
   
      - "How helpful is the checker towards manual testing?"
     
      - "How do these checkers work? Are there certain scenarios where 1 > other?"
         
    * Set up performance evaluation / Create outline for final report
         
       - Quantitative/qualitative way to present findings
 ___________________________________________________________________________________________________________________________
 
  Performance Evaluation - (7/18 - 7/22)
  
   * Use checkers on websites (a lot of this work of getting acquainted with the checkers and their functionality 
   should have already been accomplished in the weeks previously so this should not take super long)
   
   * Collect data & observations 
 ___________________________________________________________________________________________________________________________
   
  Analysis and Conclusion - (7/25 - 7/29 and 8/1 - 8/5)
  
  (7/25 - 7/29) 
  
    * Organize & Analyze data
    
    * Write final report
    
       --> Word, PDF, Slidedoc
       
  (8/1 - 8/5)
  
      * Present!
_______________________________________________________________________________________________________________________________
